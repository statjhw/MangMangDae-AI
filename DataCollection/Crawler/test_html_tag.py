import time
import requests
from bs4 import BeautifulSoup
from driver import get_chrome_driver
from logger import get_logger
from selenium.common.exceptions import TimeoutException, NoSuchElementException, ElementClickInterceptedException
from selenium.webdriver.common.by import By
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.support.ui import WebDriverWait

logger = get_logger(__name__)

def requests_get(self, url: str) -> requests.Response:
    headers = {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:136.0) Gecko/20100101 Firefox/136.0",
        "Referer": "https://www.wanted.co.kr/",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
        "Accept-Language": "ko,en-US;q=0.9,en;q=0.8",
        "Connection": "keep-alive"
    }
    with requests.Session() as s:
        response = s.get(url, headers=headers)
    return response

def test_html_tag():
    url = "https://www.wanted.co.kr/wd/295766"
    try:
        driver = get_chrome_driver()
        driver.get(url)
    except Exception as e:
        logger.error(f"âŒ {url} â–¶ï¸ í´ë¦­ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: {e}")
        return False
    
    try:
        # ì‚¬ì§„ì˜ HTML êµ¬ì¡°ì— ë§ê²Œ ë” êµ¬ì²´ì ì¸ ì„ íƒì ì‚¬ìš©
        primary_selector = "//span[@class='Button_Button__label__J05SX' and text()='ìƒì„¸ ì •ë³´ ë” ë³´ê¸°']/ancestor::button"
        elements = driver.find_elements(By.XPATH, primary_selector)
        logger.info(f"ìƒì„¸ ì •ë³´ ë²„íŠ¼ ìš”ì†Œ ê°œìˆ˜: {len(elements)}")
        
        current_selector = primary_selector
        
        if not elements: 
            logger.info(f"{url} -> ê¸°ë³¸ ì„ íƒìë¡œ ë²„íŠ¼ ìš”ì†Œ ì—†ìŒ")
            # ëŒ€ì•ˆ ì„ íƒìë“¤ ì‹œë„
            fallback_selectors = [
                "//button[contains(@class, 'Button_Button__root')]//span[text()='ìƒì„¸ ì •ë³´ ë” ë³´ê¸°']/..",
                "//span[text()='ìƒì„¸ ì •ë³´ ë” ë³´ê¸°']/ancestor::button",
                "//button[.//span[text()='ìƒì„¸ ì •ë³´ ë” ë³´ê¸°']]"
            ]
            logger.info(f"fallback_selectors: {fallback_selectors}")
            for selector in fallback_selectors:
                try:
                    elements = driver.find_elements(By.XPATH, selector)
                    if elements:
                        logger.info(f"ëŒ€ì•ˆ ì„ íƒìë¡œ ì°¾ìŒ: {selector}, ìš”ì†Œ ê°œìˆ˜: {len(elements)}")
                        current_selector = selector
                        break
                except Exception as e:
                    logger.warning(f"ëŒ€ì•ˆ ì„ íƒì ì‹¤íŒ¨ {selector}: {e}")
                    continue
        
        if elements:
            wait = WebDriverWait(driver, 5)
            more_button = wait.until(
                EC.element_to_be_clickable((By.XPATH, current_selector))
            )
            more_button.click()
            time.sleep(3)

    except TimeoutException:
        logger.warning(f"{url} -> ë²„íŠ¼ì´ 5ì´ˆ ë‚´ì— clickable ìƒíƒœê°€ ë˜ì§€ ì•ŠìŒ")
    except ElementClickInterceptedException:
        logger.warning(f"ğŸš« {url} â–¶ï¸ í´ë¦­ ì‹œ ë‹¤ë¥¸ ìš”ì†Œì— ê°€ë ¤ì§")
    except Exception as e:
        logger.error(f"âŒ {url} â–¶ï¸ í´ë¦­ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: {e}")
        return False

    page_source = driver.page_source
    soup = BeautifulSoup(page_source, "html.parser")
    
    #ë°ì´í„° ì •ë³´ ì‹¤í—˜í•˜ê¸°
    
    ### ì§ì—… ì´ë¦„ ì°¾ê¸°
    try:
        job_title = soup.find("h1", class_="wds-58fmok").text.strip()
        logger.info(f"job_title: {job_title}")
    except Exception as e:
        logger.error(f"job_title ì°¾ê¸° ì‹¤íŒ¨ : {e}")
        return False
    
    ### íšŒì‚¬ ì´ë¦„ ì°¾ê¸°
    try:
        company_name_element = soup.find(
                        "strong", class_="CompanyInfo_CompanyInfo__name__sBeI6"
                    )
        company_name = (
            company_name_element.text.strip() if company_name_element else None
        )
        company_link = soup.find(
            "a", class_="JobHeader_JobHeader__Tools__Company__Link__NoBQI"
        )
        company_id = (
            company_link["href"].split("/")[-1] if company_link else None
        )
        logger.info(f"company_name: {company_name}")
        logger.info(f"company_id: {company_id}")

    except Exception as e:
        logger.error(f"company_name ì°¾ê¸° ì‹¤íŒ¨ : {e}")
        return False
    
    ### íšŒì‚¬ ìƒì„¸ ì •ë³´ ì°¾ê¸°
    try:
        job_description_article = soup.find(
                            "article", class_="JobDescription_JobDescription__s2Keo"
                        )
        if job_description_article:
            position_detail_h2 = job_description_article.find(
                "h2", class_="wds-16rl0sf"
            )
            if position_detail_h2 and position_detail_h2.text.strip() == "í¬ì§€ì…˜ ìƒì„¸":
                position_detail_div = position_detail_h2.find_next_sibling(
                    "div", class_="JobDescription_JobDescription__paragraph__wrapper__WPrKC"
                )
                if position_detail_div:
                    position_detail_span = position_detail_div.find(
                        "span", class_="wds-h4ga6o"
                    )
                    if position_detail_span:
                        position_detail_text = position_detail_span.get_text(separator="\n").strip()
                        logger.info(f"position_detail_text: {position_detail_text}")
                    else:
                        logger.info(f"position_detail_span ì—†ìŒ")
                else:
                    logger.info(f"position_detail_div ì—†ìŒ")
            else:
                logger.info(f"position_detail_h2 ì—†ìŒ")

            section_divs = job_description_article.find_all(
                "div", class_="JobDescription_JobDescription__paragraph__87w8I"
            )
            for section_div in section_divs:
                h3 = section_div.find("h3", class_="wds-17nsd6i")
                if h3:
                    section_title = h3.text.strip()
                    content_span = section_div.find("span", class_="wds-h4ga6o")
                    if content_span:
                        content_text = content_span.get_text(
                            separator="\n"
                        ).strip()
                        content_lines = [
                            line.strip()
                            for line in content_text.split("\n")
                            if line.strip()
                        ]
                        if content_lines and content_lines[0].startswith("â€¢"):
                            items = [
                                line.lstrip("â€¢ ").strip()
                                for line in content_lines
                            ]
                            logger.info(f"section_title: {section_title}")
                            logger.info(f"items: {items}")
                        else:
                            logger.info(f"section_title: {section_title}")
                            logger.info(f"content_text: {content_text}")
                else:
                    logger.info(f"h3 ì—†ìŒ")

            logger.info(f"position_detail_text: {position_detail_text}")

    except Exception as e:
        logger.error(f"position_detail_text ì°¾ê¸° ì‹¤íŒ¨ : {e}")
        return False
    
    ### ë§ˆê°ì¼ ì°¾ê¸°
    try:
        deadline = soup.find("span", class_="wds-1u1yyy").get_text()
        logger.info(f"deadline: {deadline}")
    except Exception as e:
        logger.error(f"deadline ì°¾ê¸° ì‹¤íŒ¨ : {e}")
        return False
    
    ### ìœ„ì¹˜ ì°¾ê¸°
    try:
        location = soup.find("span", class_="wds-1td1qmv").get_text()
        logger.info(f"location: {location}")
    except Exception as e:
        logger.error(f"location ì°¾ê¸° ì‹¤íŒ¨ : {e}")
        return False
    
    ### ê²½ë ¥ ì •ë³´ ì°¾ê¸°
    try:
        career_info = soup.find_all("span", class_="JobHeader_JobHeader__Tools__Company__Info__b9P4Y wds-1pe0q6z")[1].get_text()
        logger.info(f"career_info: {career_info}")
    except Exception as e:
        logger.error(f"career_info ì°¾ê¸° ì‹¤íŒ¨ : {e}")
        return False

    driver.quit()

    result = {
        "url": url,
        "job_title": job_title,
        "company_name": company_name,
        "company_id": company_id,
        "position_detail_text": position_detail_text,
        "deadline": deadline,
        "location": location,
        "career": career_info,
    }
    logger.info(f"result: {result}")
    return True

if __name__ == "__main__":
    if test_html_tag():
        logger.info("í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
    else:
        logger.error("í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")