from typing import Dict, Any, Union
import logging
import json
import os
from langchain_core.tools import tool
from langsmith import traceable
from WorkFlow.Util.utils import advice_chain, summary_memory_chain, final_answer_chain, intent_analysis_chain, contextual_qa_prompt_chain, reformulate_query_chain
from retrieval.embeddings import get_vector_store, retrieve
from config import get_tavily_tool, RateLimitError
import re

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# LangSmith í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["LANGCHAIN_PROJECT"] = os.getenv("LANGSMITH_PROJECT", "job_advisor")

# ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”
vector_store = get_vector_store()
tavily_tool = get_tavily_tool()

@tool
@traceable(name="analyze_intent_tool")
def analyze_intent_tool(state: Dict[str, Any]) -> Dict[str, str]:
    """ëŒ€í™” ê¸°ë¡ê³¼ í˜„ì¬ ì§ˆë¬¸ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ì ì˜ë„ ë¶„ì„"""
    summary = state.get("summary")
    chat_history = state.get("chat_history", [])
    question = state.get("parsed_input", {}).get("question", "")
    
    context_for_llm = ""
    # ìš”ì•½ë³¸ì´ ì¡´ì¬í•˜ë©´, ìš”ì•½ë³¸ì„ ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©
    if summary:
        context_for_llm = f"ì´ì „ ëŒ€í™” ìš”ì•½:\n{summary}"
        logger.info("Using conversation summary for intent analysis.")
    # ìš”ì•½ë³¸ì´ ì—†ìœ¼ë©´ (ì´ˆê¸° ëŒ€í™”), ì „ì²´ ëŒ€í™” ê¸°ë¡ì„ ì‚¬ìš©
    else:
        context_for_llm = "\n".join([f"User: {turn['user']}\nAssistant: {turn['assistant']}" for turn in chat_history])
        logger.info("Using full chat history for intent analysis (no summary yet).")
    # ì˜ë„ ë¶„ì„ ì²´ì¸ ì‹¤í–‰
    intent_result = intent_analysis_chain.invoke({
        "chat_history": context_for_llm,
        "question": question
    }).content.strip()

    # ì‚¬ìš©ìê°€ ë¶ˆë§Œì¡±ì„ í‘œí•˜ë©° ìƒˆë¡œìš´ ê²€ìƒ‰ì„ ì›í•  ê²½ìš°, ì´ì „ ì¶”ì²œì„ ì œì™¸ ëª©ë¡ì— ì¶”ê°€
    if intent_result == 'new_search' and state.get('job_list'):
        # ì´ì „ í„´ì—ì„œ ì œì‹œí–ˆë˜ í›„ë³´ ëª©ë¡('job_list')ì—ì„œ URLë“¤ì„ ì¶”ì¶œ
        previous_urls = [job.get('document', '') for job in state.get('job_list', [])]
        
        # ì •ê·œì‹ìœ¼ë¡œ ê° ë¬¸ì„œì—ì„œ URLë§Œ ë½‘ì•„ëƒ„
        excluded_urls = []
        for doc in previous_urls:
            match = re.search(r"ì±„ìš©ê³µê³  URL:\s*(.*)", doc)
            if match:
                excluded_urls.append(match.group(1).strip())

        # ê¸°ì¡´ ì œì™¸ ëª©ë¡ì— ìƒˆë¡œìš´ URLë“¤ì„ ì¶”ê°€
        current_excluded = state.get('excluded_jobs', [])
        current_excluded.extend(excluded_urls)
        
        # ì¤‘ë³µì„ ì œê±°í•˜ì—¬ state ì—…ë°ì´íŠ¸
        state['excluded_jobs'] = list(set(current_excluded))
        logger.info(f"Adding {len(excluded_urls)} jobs to the exclusion list for the next search.")
    
    elif intent_result == 'select_job':
        logger.info("Intent is 'select_job', proceeding to load the selected document.")


    return {"intent": intent_result}

def _parse_job_posting(text):
    """ë‹¨ì¼ ì±„ìš© ê³µê³  ë¬¸ì„œ(text)ë¥¼ íŒŒì‹±í•´ ë”•ì…”ë„ˆë¦¬ë¡œ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜"""
    data = {}

    data["ì§ë¬´"] = re.search(r"ì§ë¬´:\s*(.*?)\n", text).group(1).strip() if re.search(r"ì§ë¬´:\s*(.*?)\n", text) else None
    data["íšŒì‚¬"] = re.search(r"íšŒì‚¬:\s*(.*?)\n", text).group(1).strip() if re.search(r"íšŒì‚¬:\s*(.*?)\n", text) else None
    data["íƒœê·¸"] = re.search(r"íƒœê·¸:\s*(.*?)\n", text).group(1).split(", ") if re.search(r"íƒœê·¸:\s*(.*?)\n", text) else None
    data["ìœ„ì¹˜"] = re.search(r"ìœ„ì¹˜:\s*(.*?)\n", text).group(1).strip() if re.search(r"ìœ„ì¹˜:\s*(.*?)\n", text) else None
    data["ë§ˆê°ì¼"] = re.search(r"ë§ˆê°ì¼:\s*(.*?)\n", text).group(1).strip() if re.search(r"ë§ˆê°ì¼:\s*(.*?)\n", text) else None
    data["ìê²© ìš”ê±´"] = re.search(r"3\. ìê²©([\s\S]*?)ìš°ëŒ€ ì‚¬í•­:", text).group(1).strip() if re.search(r"3\. ìê²©([\s\S]*?)ìš°ëŒ€ ì‚¬í•­:", text) else None
    data["ìš°ëŒ€ ì‚¬í•­"] = re.search(r"ìš°ëŒ€ ì‚¬í•­:\n([\s\S]*?)í˜œíƒ ë° ë³µì§€:", text).group(1).strip() if re.search(r"ìš°ëŒ€ ì‚¬í•­:\n([\s\S]*?)í˜œíƒ ë° ë³µì§€:", text) else None
    data["í˜œíƒ ë° ë³µì§€"] = re.search(r"í˜œíƒ ë° ë³µì§€:\n([\s\S]*?)ì±„ìš© ê³¼ì •:", text).group(1).strip() if re.search(r"í˜œíƒ ë° ë³µì§€:\n([\s\S]*?)ì±„ìš© ê³¼ì •:", text) else None
    data["ì±„ìš© ê³¼ì •"] = re.search(r"ì±„ìš© ê³¼ì •:\s*(.*?)\n", text).group(1).strip() if re.search(r"ì±„ìš© ê³¼ì •:\s*(.*?)\n", text) else None
    return data

@tool
@traceable(name="recommend_jobs_tool")
def recommend_jobs_tool(state: Union[Dict[str, Any], str]) -> Dict[str, Any]:
    """ì§ë¬´ ì¶”ì²œ (vector_store.similarity_search, ì¬ê²€ìƒ‰ ì§€ì›)."""
    # ì…ë ¥ ì²˜ë¦¬
    if isinstance(state, str):
        try:
            state = json.loads(state)
        except:
            try:
                state = eval(state)
            except:
                pass
    
    # stateê°€ ì•„ë‹Œ ê²½ìš° ì´ì „ ë‹¨ê³„ì˜ state ê°€ì ¸ì˜¤ê¸°
    if not isinstance(state, dict) or "parsed_input" not in state:
        logger.warning("Invalid state provided to recommend_jobs_tool: %s", state)
        return {"error": "ì§ë¬´ ì¶”ì²œì„ ìœ„í•œ ìœ íš¨í•œ ìƒíƒœê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}

    user_profile = state.get("parsed_input", {})

    base_query = user_profile.get("question", "")
    query = f"[query] {base_query}" 
    
    try:
        doc_scores, doc_texts = retrieve(query, exclude_urls=state.get("excluded_jobs", []))
        if not doc_texts:
            return {"job_list": []}
        
        # LLMìœ¼ë¡œ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ëŠ” ëŒ€ì‹ , ì „ì²´ í›„ë³´ ëª©ë¡ì„ stateì— ì €ì¥
        candidate_jobs = []
        for i, text in enumerate(doc_texts):
            parsed_data = _parse_job_posting(text)
            candidate_jobs.append({
                "index": i + 1,
                "company": parsed_data.get("íšŒì‚¬", "ì •ë³´ ì—†ìŒ"),
                "title": parsed_data.get("ì§ë¬´", "ì •ë³´ ì—†ìŒ"),
                "score": doc_scores[i],
                "document": text
            })
        
        return {"job_list": candidate_jobs}

    except Exception as e:
        logger.error("Job recommendation (retrieval) error: %s", str(e))
        
    return {"job_list": []}

@tool
@traceable(name="present_candidates_tool")
def present_candidates_tool(state: Dict[str, Any]) -> Dict[str, str]:
    """job_listë¥¼ ì‚¬ìš©ìì—ê²Œ ë³´ì—¬ì¤„ ìµœì¢… ë‹µë³€ í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…í•©ë‹ˆë‹¤."""
    job_list = state.get("job_list", [])
    if not job_list:
        return {"final_answer": "ì£„ì†¡í•˜ì§€ë§Œ, í˜„ì¬ ì¡°ê±´ì— ë§ëŠ” ì±„ìš© ê³µê³ ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì¡°ê±´ìœ¼ë¡œ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì‹œê² ì–´ìš”?"}
    
    response_lines = ["ë‹¤ìŒì€ ì¶”ì²œí•˜ëŠ” ì±„ìš© ê³µê³  ëª©ë¡ì…ë‹ˆë‹¤. ë” ìì„¸íˆ ì•Œì•„ë³´ê³  ì‹¶ì€ ê³µê³ ì˜ ë²ˆí˜¸ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.\n"]
    for job in job_list:
        # ê° ë¬¸ì„œì˜ ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ íŒŒì‹±í•˜ì—¬ ì£¼ìš” ì •ë³´ ì¶”ì¶œ
        print(job)
        doc_text = job.get('document', '')
        # _parse_job_postingì´ Noneì„ ë°˜í™˜í•  ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ë¹ˆ dictë¡œ ì²˜ë¦¬
        parsed_data = _parse_job_posting(doc_text) or {}
        
        # ë³´ì—¬ì¤„ ì •ë³´ ê°€ê³µ
        company = parsed_data.get("íšŒì‚¬", "ì •ë³´ ì—†ìŒ")
        title = parsed_data.get("ì§ë¬´", "ì •ë³´ ì—†ìŒ")
        location = parsed_data.get("ìœ„ì¹˜", "ì •ë³´ ì—†ìŒ")
        
        # í•µì‹¬ íƒœê·¸ 3ê°œë§Œ ì¶”ì¶œ
        tags = parsed_data.get("íƒœê·¸", [])
        key_tags = f"ğŸ·ï¸ í•µì‹¬ íƒœê·¸: {' / '.join(tags[:3])}" if tags else ""
        
        # (ìˆ˜ì •ëœ ë¶€ë¶„) ìê²© ìš”ê±´ì„ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì™€ì„œ ì²˜ë¦¬
        summary = "" # summary ë³€ìˆ˜ ì´ˆê¸°í™”
        qualifications_text = parsed_data.get("ìê²© ìš”ê±´")

        # qualifications_textê°€ ì‹¤ì œ ë¬¸ìì—´ì¼ ë•Œë§Œ ìš”ì•½ ìƒì„±
        if qualifications_text and isinstance(qualifications_text, str):
            first_line = qualifications_text.split('\n')[0].strip('- ')
            if first_line: # ì²« ì¤„ì´ ë¹„ì–´ìˆì§€ ì•Šë‹¤ë©´
                summary = f"âœ¨ ì£¼ìš” ìš”ê±´: {first_line}"

        # ìµœì¢… ì¶œë ¥ ë¬¸ìì—´ ì¡°í•©
        response_lines.append(f"**{job['index']}. {company} - {title}**")
        response_lines.append(f"ğŸ“ ìœ„ì¹˜: {location}")
        if key_tags:
            response_lines.append(key_tags)
        if summary: # summaryì— ë‚´ìš©ì´ ìˆì„ ë•Œë§Œ ì¶”ê°€
            response_lines.append(summary)
        response_lines.append("-" * 20)
    
    response_lines.append("\në” ìì„¸íˆ ì•Œì•„ë³´ê³  ì‹¶ì€ ê³µê³ ì˜ ë²ˆí˜¸ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”. í•´ë‹¹ ê³µê³ ì— ëŒ€í•œ ì‹¬ì¸µ ë¶„ì„ì„ ì œê³µí•´ ë“œë¦½ë‹ˆë‹¤.")
    return {"final_answer": "\n".join(response_lines)}

# ì‹ ê·œ ë„êµ¬ 2: ì‚¬ìš©ì ì„ íƒ ë¡œë“œ
@tool
@traceable(name="load_selected_job_tool")
def load_selected_job_tool(state: Dict[str, Any]) -> Dict[str, Any]:
    """ì‚¬ìš©ì ì…ë ¥ì—ì„œ ì„ íƒëœ ë²ˆí˜¸ë¥¼ íŒŒì‹±í•˜ì—¬ selected_jobì„ ì„¤ì •í•©ë‹ˆë‹¤."""
    user_question = state.get("parsed_input", {}).get("question", "")
    job_list = state.get("job_list", [])
    
    # "1ë²ˆ", "ë‘ë²ˆì§¸", "2" ë“± ìˆ«ì ì¶”ì¶œ
    match = re.search(r'\d+', user_question)
    if match:
        try:
            selected_index = int(match.group(0))
            for job in job_list:
                if job.get('index') == selected_index:
                    logger.info(f"Selected job by index: {selected_index}")
                    return {"selected_job": job.get('document')}
        except (ValueError, IndexError):
            pass # ìˆ«ìë¥¼ ì°¾ì•˜ì§€ë§Œ ìœ íš¨í•˜ì§€ ì•Šì€ ê²½ìš°, ì•„ë˜ì˜ ì´ë¦„ ê¸°ë°˜ìœ¼ë¡œ ë„˜ì–´ê°

    # 2. ìˆ«ìê°€ ì—†ìœ¼ë©´ íšŒì‚¬ëª… ê¸°ë°˜ ì„ íƒ ì‹œë„
    for job in job_list:
        company_name = job.get('company')
        # ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— íšŒì‚¬ëª…ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        if company_name and company_name in user_question:
            logger.info(f"Selected job by company name: {company_name}")
            return {"selected_job": job.get('document')}
            
    # ìµœì¢…ì ìœ¼ë¡œ ì•„ë¬´ê²ƒë„ ì°¾ì§€ ëª»í•œ ê²½ìš°
    logger.warning(f"Could not parse a valid selection from user input: '{user_question}'")
    return {"selected_job": "ì˜¤ë¥˜: ìœ íš¨í•œ ê³µê³ ë¥¼ ì„ íƒí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ëª©ë¡ì— ìˆëŠ” ë²ˆí˜¸ë‚˜ íšŒì‚¬ëª…ì„ í¬í•¨í•˜ì—¬ ë‹¤ì‹œ ë§ì”€í•´ì£¼ì„¸ìš”."}


@tool
@traceable(name="reformulate_query_tool")
def reformulate_query_tool(state: Dict[str, Any]) -> Dict[str, str]:
    """ì „ì²´ ëŒ€í™” ë§¥ë½ì„ ë°”íƒ•ìœ¼ë¡œ ìƒˆë¡œìš´ ê²€ìƒ‰ì–´ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    logger.info("Reformulating search query based on conversation context.")
    
    summary = state.get("summary", "")
    chat_history = state.get("chat_history", [])
    question = state.get("parsed_input", {}).get("question", "") # ì˜ˆ: "ë‹¤ë¥¸ê±° ì°¾ì•„ì¤˜"
    
    # ìš”ì•½ë³¸ ë˜ëŠ” ì „ì²´ ê¸°ë¡ì„ ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©
    context = summary if summary else "\n".join([f"User: {turn['user']}" for turn in chat_history])

    try:
        # LLMì„ í˜¸ì¶œí•˜ì—¬ ìƒˆë¡œìš´ ê²€ìƒ‰ì–´ ìƒì„±
        new_query = reformulate_query_chain.invoke({
            "context": context,
            "question": question
        }).content.strip()
        
        logger.info(f"Reformulated query: '{new_query}'")
        
        # ìƒì„±ëœ ìƒˆ ì¿¼ë¦¬ë¥¼ 'parsed_input'ì˜ questionì— ë®ì–´ì¨ì„œ ë‹¤ìŒ ë…¸ë“œë¡œ ì „ë‹¬
        # ì´ë ‡ê²Œ í•˜ë©´ recommend_jobs_toolì€ ë³„ë„ ìˆ˜ì • ì—†ì´ ì´ ì¿¼ë¦¬ë¥¼ ì‚¬ìš©í•˜ê²Œ ë¨
        updated_parsed_input = state.get("parsed_input", {}).copy()
        updated_parsed_input["question"] = new_query
        
        return {"parsed_input": updated_parsed_input}

    except Exception as e:
        logger.error(f"Query reformulation error: {e}", exc_info=True)
        # ì‹¤íŒ¨ ì‹œ, ì›ë˜ ì§ˆë¬¸ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        return {"parsed_input": state.get("parsed_input")}


@tool
@traceable(name="search_company_info_tool")
def search_company_info_tool(state: Dict[str, Any]) -> Dict[str, str]:
    """íšŒì‚¬ ì •ë³´ë¥¼ ì›¹ì—ì„œ ê²€ìƒ‰í•˜ë©°, intentì— ë”°ë¼ ê²€ìƒ‰ì–´ì˜ ë§¥ë½ì„ ë™ì ìœ¼ë¡œ êµ¬ì„±í•©ë‹ˆë‹¤."""
    
    selected_job_text = state.get("selected_job")
    if not selected_job_text:
        return {"search_result": "ë¶„ì„í•  ì§ë¬´ê°€ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}
    
    try:
        parsed_job = _parse_job_posting(selected_job_text)
        company_name = parsed_job.get("íšŒì‚¬")
        if not company_name:
            return {"search_result": "ê³µê³ ì—ì„œ íšŒì‚¬ ì´ë¦„ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."}

        # --- [í•µì‹¬ ìˆ˜ì •] intentì— ë”°ë¼ ì§ˆë¬¸ì˜ ì¶œì²˜ë¥¼ ë‹¤ë¥´ê²Œ ì„¤ì • ---
        intent = state.get("intent")
        contextual_question = ""

        # ì‚¬ìš©ìê°€ í›„ë³´ ëª©ë¡ì—ì„œ ë°©ê¸ˆ ì„ íƒí•œ ê²½ìš°, ì´ì „ í„´ì˜ ì›ë˜ ê²€ìƒ‰ì–´ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ì‚¬ìš©
        if intent == "select_job":
            chat_history = state.get("chat_history", [])
            # chat_history[-1]ì€ í˜„ì¬ í„´("2ë²ˆ ì•Œë ¤ì¤˜"), chat_history[-2]ê°€ ì´ì „ í„´ì˜ ì§ˆë¬¸
            if len(chat_history) >= 2:
                contextual_question = chat_history[-2].get("user", "")
                logger.info(f"Using previous question for context: '{contextual_question}'")
            else:
                # ì˜ˆì™¸ì ì¸ ê²½ìš°, í˜„ì¬ í„´ì˜ ì§ˆë¬¸ì„ fallbackìœ¼ë¡œ ì‚¬ìš© (ê±°ì˜ ë°œìƒí•˜ì§€ ì•ŠìŒ)
                contextual_question = state.get("parsed_input", {}).get("question", "")
        else:
            # ë‹¤ë¥¸ ëª¨ë“  ê²½ìš°ì—ëŠ” í˜„ì¬ í„´ì˜ ì§ˆë¬¸ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            contextual_question = state.get("parsed_input", {}).get("question", "")
        # --- ìˆ˜ì • ë ---

        search_query = f"{company_name} {contextual_question}"
        logger.info(f"Executing web search with query: '{search_query}'")
        
        search_results = tavily_tool.invoke({"query": search_query})
        
        if not isinstance(search_results, list):
            search_results = [search_results]

        # ì œëª©ê³¼ 300ìë¡œ ìš”ì•½ëœ ë‚´ìš©ì„ ì¡°í•©
        result_lines = []
        for result in search_results:
            title = result.get('title', 'ì œëª© ì—†ìŒ')
            content = ' '.join(str(result.get('content', '')).strip().split())
            truncated_content = content[:300] + '...' if len(content) > 300 else content
            result_lines.append(f"Title: {title}\nContent: {truncated_content}")
        
        formatted_results = "\n\n".join(result_lines)
        
        return {"search_result": formatted_results}

    except Exception as e:
        logger.error(f"Error in search_company_info_tool: {e}", exc_info=True)
        return {"search_result": "ì›¹ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."}

@tool
@traceable(name="get_preparation_advice_tool")
def get_preparation_advice_tool(state: Union[Dict[str, Any], str]) -> Dict[str, Any]:
    """ì§ë¬´ ì¤€ë¹„ ì¡°ì–¸ ì œê³µ."""
    # ì…ë ¥ ì²˜ë¦¬
    if isinstance(state, str):
        try:
            state = json.loads(state)
        except:
            try:
                state = eval(state)
            except:
                pass
    
    # stateê°€ ì•„ë‹Œ ê²½ìš° ì´ì „ ë‹¨ê³„ì˜ state ê°€ì ¸ì˜¤ê¸°
    if not isinstance(state, dict) or "parsed_input" not in state:
        logger.warning("Invalid state provided to get_preparation_advice_tool: %s", state)
        return {"error": "ì§ë¬´ ì¤€ë¹„ ì¡°ì–¸ ì œê³µì„ ìœ„í•œ ìœ íš¨í•œ ìƒíƒœê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}
    
    
    if "selected_job" not in state or state["selected_job"] is None:
        logger.warning("No selected_job in state for preparation advice")
        state["preparation_advice"] = "ì„ íƒëœ ì§ë¬´ ì •ë³´ê°€ ì—†ì–´ ì¤€ë¹„ ì¡°ì–¸ì„ ì œê³µí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        return state
    
    try:
        # ì‚¬ìš©ì í”„ë¡œí•„ êµ¬ì„±
        user_profile = (
        f"í•™ë ¥: {state['parsed_input']['education']}, "
        f"ê²½ë ¥: {state['parsed_input']['experience']}, "
        f"í¬ë§ ì§ë¬´: {state['parsed_input']['desired_job']}, "
        f"ê¸°ìˆ  ìŠ¤íƒ: {', '.join(state['parsed_input']['tech_stack'])}",
        f"í¬ë§ ê·¼ë¬´ì§€ì—­: {state['parsed_input']['location']}",
    )
        
        # ì§ë¬´ ì •ë³´ êµ¬ì„±
        selected_job_text = state["selected_job"]

        # LLM ì²´ì¸ìœ¼ë¡œ ì¤€ë¹„ ì¡°ì–¸ ìƒì„±
        state["preparation_advice"] = advice_chain.invoke({
            "user_profile": user_profile,
            "job_data": selected_job_text
        }).content
        
    except Exception as e:
        logger.error("Preparation advice generation error: %s", str(e))
        state["preparation_advice"] = f"ì¤€ë¹„ ì¡°ì–¸ ìƒì„± ì˜¤ë¥˜: {str(e)}"
    
    return state

@tool
@traceable(name="contextual_qa_tool")
def contextual_qa_tool(state: Dict[str, Any]) -> Dict[str, Any]:
    """ì„ íƒëœ ì§ë¬´ì™€ ì›¹ ê²€ìƒ‰ì„ í†µí•´ í›„ì† ì§ˆë¬¸ì— ë‹µë³€"""
    question = state["parsed_input"]["question"]
    company_context = state.get("selected_job", "ì„ íƒëœ ì±„ìš© ê³µê³ ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # ì›¹ ê²€ìƒ‰ì´ í•„ìš”í•œ ì§ˆë¬¸ì¸ì§€ íŒë‹¨í•˜ì—¬ search_company_info_tool ì¬í™œìš©
    web_search_needed_keywords = ["ì—°ë´‰", "ë‰´ìŠ¤", "í‰íŒ", "ìµœì‹ ", "ì´ìŠˆ"]
    web_search_context = ""
    if any(keyword in question for keyword in web_search_needed_keywords):
        search_result_state = search_company_info_tool.func(state)
        web_search_context = search_result_state.get("search_result", "")

    # ë‹µë³€ ìƒì„± ì²´ì¸ ì‹¤í–‰
    answer = contextual_qa_prompt_chain.invoke({
        "company_context": company_context,
        "web_search_context": web_search_context,
        "question": question
    }).content

    return {"final_answer": answer}


@tool
@traceable(name="generate_final_answer_tool")
def generate_final_answer_tool(state: Dict[str, Any]) -> Dict[str, str]:
    """ëŒ€í™”ì˜ intentì— ë”°ë¼ ê°ê¸° ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ìµœì¢… ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    intent = state.get("intent", "chit_chat")
    logger.info(f"Generating final answer for intent: '{intent}'")
    final_answer = ""
    
    try:
        # ìœ í˜• 1: ë‹¨ìˆœ ì¸ì‚¬ ë˜ëŠ” ë¶€ì ì ˆí•œ ì§ˆë¬¸
        if intent == "chit_chat":
            final_answer = "ì£„ì†¡í•©ë‹ˆë‹¤. ì €ëŠ” ì±„ìš© ê´€ë ¨ ì§ˆë¬¸ì—ë§Œ ë‹µë³€ì„ ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê¶ê¸ˆí•˜ì‹  ì§ë¬´ë‚˜ íšŒì‚¬ì— ëŒ€í•´ ë§ì”€í•´ì£¼ì„¸ìš”."

        # ìœ í˜• 2: 'ì²˜ìŒ ê²€ìƒ‰' ë˜ëŠ” 'ë‹¤ë¥¸ê±° ì°¾ì•„ì¤˜' í›„, í›„ë³´ ëª©ë¡ì„ ì œì‹œí•˜ëŠ” ê²½ìš°
        elif intent in ["initial_search", "new_search"]:
            # present_candidates_toolì—ì„œ ìƒì„±ëœ ë‹µë³€("...ë²ˆí˜¸ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.")ì„ ìµœì¢… ë‹µë³€ìœ¼ë¡œ ì‚¬ìš©
            final_answer = state.get("final_answer", "ì¶”ì²œ ëª©ë¡ì„ ìƒì„±í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        
        # ìœ í˜• 3: ì‚¬ìš©ìê°€ íŠ¹ì • íšŒì‚¬ë¥¼ 'ì„ íƒ'í•œ í›„, ëª¨ë“  ì •ë³´ë¥¼ ì¢…í•©í•œ ì‹¬ì¸µ ë¶„ì„ ê²°ê³¼ë¥¼ ì œê³µí•˜ëŠ” ê²½ìš°
        elif intent == "select_job":
            user_profile = (
                f"í•™ë ¥: {state.get('parsed_input', {}).get('education', '')}, "
                f"ê²½ë ¥: {state.get('parsed_input', {}).get('experience', '')}, "
                f"í¬ë§ ì§ë¬´: {state.get('parsed_input', {}).get('desired_job', '')}, "
                f"ê¸°ìˆ  ìŠ¤íƒ: {', '.join(state.get('parsed_input', {}).get('tech_stack', []))}, "
                f"í¬ë§ ê·¼ë¬´ì§€ì—­: {state.get('parsed_input', {}).get('location', '')}"
            )
            question = state.get("parsed_input", {}).get("question", "")
            
            # ëª¨ë“  ë¶„ì„(íšŒì‚¬ì •ë³´, ì¤€ë¹„ì¡°ì–¸ ë“±)ì„ ì¢…í•©í•˜ì—¬ ìµœì¢… ë‹µë³€ ìƒì„±
            final_answer = final_answer_chain.invoke({
                "user_profile": user_profile,
                "question": question,
                "selected_job": state.get("selected_job", ""),
                "search_result": state.get("search_result", ""),
                "preparation_advice": state.get("preparation_advice", "")
            }).content

        # ìœ í˜• 4: ì‹¬ì¸µ ë¶„ì„ì´ ëë‚œ í›„, ì¶”ê°€ì ì¸ 'í›„ì† ì§ˆë¬¸'ì— ë‹µë³€í•˜ëŠ” ê²½ìš°
        elif intent == "follow_up_qa":
            # contextual_qa_toolì—ì„œ ì´ë¯¸ ìƒì„±í•œ ë‹µë³€ì„ ìµœì¢… ë‹µë³€ìœ¼ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
            final_answer = state.get("final_answer", "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        
        else:
            final_answer = "ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­ì„ ì´í•´í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë§ì”€í•´ì£¼ì„¸ìš”."
            
    except Exception as e:
        logger.error(f"Final answer generation error: {e}", exc_info=True)
        final_answer = "ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

    return {"final_answer": final_answer}

@tool
@traceable(name="record_history_tool")
def record_history_tool(state: Dict[str, Any]) -> Dict[str, Any]:
    """ìƒì„±ëœ ìµœì¢… ë‹µë³€ì„ chat_historyì— ê¸°ë¡í•˜ê³ , íŒŒì¼ë¡œ ì €ì¥ ë° ìš”ì•½í•©ë‹ˆë‹¤."""
    final_answer = state.get("final_answer", "")
    
    # 1. ìµœì¢… ë‹µë³€ì„ chat_historyì— ì—…ë°ì´íŠ¸
    if state.get("chat_history"):
        state["chat_history"][-1]["assistant"] = final_answer
    
            
    # 2. ëŒ€í™” í„´ ê¸¸ì´ì— ë”°ë¥¸ ìš”ì•½ 
    if state.get("conversation_turn", 0) % 3 == 0 and state.get("conversation_turn", 0) > 0:
        logger.info("Summarizing conversation history...")
        chat_history_str = "\n".join([f"User: {msg.get('user', '')}\nAssistant: {msg.get('assistant', '')}" for msg in state.get("chat_history", [])])
        summary_input = {"summary": state.get("summary", ""), "new_lines": chat_history_str}
        new_summary = summary_memory_chain.invoke(summary_input).content
        state["summary"] = new_summary
        # state["chat_history"] = [] # ìš”ì•½ í›„ í˜„ì¬ ëŒ€í™” ë‚´ìš©ì€ ë¹„ì›Œì¤Œ
        logger.info(f"Conversation summarized and history cleared.")

    # ì´ ë„êµ¬ëŠ” stateë¥¼ ì§ì ‘ ìˆ˜ì •í–ˆìœ¼ë¯€ë¡œ, ë³€ê²½ëœ state ìì²´ë¥¼ ë°˜í™˜
    return state