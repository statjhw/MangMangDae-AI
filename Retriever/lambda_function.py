import json
import logging
import os
import re
from typing import Dict, List, Tuple, Union
from opensearchpy import OpenSearch, RequestsHttpConnection
from requests_aws4auth import AWS4Auth
import boto3
from sentence_transformers import SentenceTransformer, CrossEncoder

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger()
logger.setLevel(logging.INFO)

# í™˜ê²½ ë³€ìˆ˜
OPENSEARCH_HOST = os.environ.get('OPENSEARCH_HOST')
OPENSEARCH_INDEX = os.environ.get('OPENSEARCH_INDEX', 'opensearch_job')
AWS_REGION = os.environ.get('AWS_REGION', 'ap-northeast-2')

# HuggingFace ìºì‹œ ë””ë ‰í† ë¦¬ë¥¼ /tmpë¡œ ì„¤ì • (Lambdaì—ì„œ ì“°ê¸° ê°€ëŠ¥í•œ ìœ ì¼í•œ ë””ë ‰í† ë¦¬)
os.environ['TRANSFORMERS_CACHE'] = '/tmp/transformers_cache'
os.environ['HF_HOME'] = '/tmp/hf_cache'
os.environ['SENTENCE_TRANSFORMERS_HOME'] = '/tmp/sentence_transformers_cache'
os.environ['TORCH_HOME'] = '/tmp/torch_cache'

# í™ˆ ë””ë ‰í† ë¦¬ë„ /tmpë¡œ ë³€ê²½
os.environ['HOME'] = '/tmp'

# ì „ì—­ ë³€ìˆ˜ (ì½œë“œ ìŠ¤íƒ€íŠ¸ ìµœì í™”)
_opensearch_client = None
_embedding_model = None
_reranker_model = None

def get_opensearch_client():
    """OpenSearch í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
    global _opensearch_client
    if _opensearch_client is None:
        logger.info("OpenSearch í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì¤‘...")
        
        if not OPENSEARCH_HOST:
            raise ValueError("OPENSEARCH_HOST í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # Lambdaì—ì„œëŠ” ìë™ìœ¼ë¡œ IAM ì—­í•  ìê²© ì¦ëª… ì‚¬ìš©
        session = boto3.Session()
        credentials = session.get_credentials()
        auth = AWS4Auth(
            credentials.access_key,
            credentials.secret_key,
            AWS_REGION,
            'es',
            session_token=credentials.token
        )
        
        _opensearch_client = OpenSearch(
            hosts=[{'host': OPENSEARCH_HOST, 'port': 443}],
            http_auth=auth,
            use_ssl=True,
            verify_certs=True,
            connection_class=RequestsHttpConnection,
            timeout=30
        )
        logger.info("âœ… OpenSearch í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
    
    return _opensearch_client

def get_embedding_model():
    """ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”"""
    global _embedding_model
    if _embedding_model is None:
        logger.info("ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
        
        # ìºì‹œ ë””ë ‰í† ë¦¬ ë¯¸ë¦¬ ìƒì„±
        import os
        cache_dir = '/tmp/sentence_transformers_cache'
        os.makedirs(cache_dir, exist_ok=True)
        
        _embedding_model = SentenceTransformer(
            'intfloat/multilingual-e5-large',
            cache_folder=cache_dir
        )
        logger.info("âœ… ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
    
    return _embedding_model

def get_reranker_model():
    """ë¦¬ë­ì»¤ ëª¨ë¸ ì´ˆê¸°í™”"""
    global _reranker_model
    if _reranker_model is None:
        logger.info("ë¦¬ë­ì»¤ ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
        
        # ìºì‹œ ë””ë ‰í† ë¦¬ ë¯¸ë¦¬ ìƒì„±
        import os
        cache_dir = '/tmp/cross_encoder_cache'
        os.makedirs(cache_dir, exist_ok=True)
        
        _reranker_model = CrossEncoder(
            'cross-encoder/ms-marco-MiniLM-L-6-v2',
            max_length=256,
            device='cpu',
            cache_folder=cache_dir
        )
        logger.info("âœ… ë¦¬ë­ì»¤ ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
    
    return _reranker_model

def format_document_for_reranking(document: Dict) -> str:
    """ë¬¸ì„œë¥¼ ë¦¬ë­í‚¹ìš© í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…"""
    if not document:
        return ""
    
    parts = []
    
    # ì£¼ìš” í•„ë“œë“¤ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    if document.get('title'):
        parts.append(f"ì§ë¬´: {document['title']}")
    if document.get('company_name'):
        parts.append(f"íšŒì‚¬: {document['company_name']}")
    if document.get('position_detail'):
        parts.append(f"í¬ì§€ì…˜ ìƒì„¸: {document['position_detail']}")
    if document.get('main_tasks') and isinstance(document['main_tasks'], list):
        parts.append(f"ì£¼ìš” ì—…ë¬´: {', '.join(document['main_tasks'])}")
    if document.get('qualifications') and isinstance(document['qualifications'], list):
        parts.append(f"ìê²© ìš”ê±´: {', '.join(document['qualifications'])}")
    if document.get('location'):
        parts.append(f"ìœ„ì¹˜: {document['location']}")
    
    return " | ".join(parts)

def _get_years_from_career(career: str) -> int:
    """'në…„', 'n ë…„' í˜•ì‹ì—ì„œ ìˆ«ì nì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    # ìˆ«ìë¥¼ ì°¾ê¸° ìœ„í•œ ì •ê·œì‹
    match = re.search(r'(\d+)', career)
    if match:
        return int(match.group(1))
    return 0  # ìˆ«ìê°€ ì—†ìœ¼ë©´ 0ë…„(ì‹ ì…)ìœ¼ë¡œ ê°„ì£¼

def _build_career_filter(career: str) -> Union[dict, None]:
    """[ì—…ê·¸ë ˆì´ë“œ ë²„ì „] ì‚¬ìš©ìì˜ career ì…ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ ì§€ëŠ¥ì ì¸ OpenSearch filter ì ˆì„ ìƒì„±í•©ë‹ˆë‹¤."""
    if not career:
        return None

    user_years = _get_years_from_career(career)

    # CASE 1: ì‚¬ìš©ìê°€ 'ì‹ ì…'ì´ê±°ë‚˜ ê²½ë ¥ì— ìˆ«ìê°€ ì—†ëŠ” ê²½ìš°
    if user_years == 0 and ("ì‹ ì…" in career or "ë¬´ê´€" in career):
        # 'ì‹ ì…', 'ê²½ë ¥ë¬´ê´€', 'ë¬´ê´€' í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¬¸ì„œë¥¼ ëª¨ë‘ ì°¾ë„ë¡ ìœ ì—°í•˜ê²Œ ì„¤ì •
        return {
            "bool": {
                "should": [
                    {"match": {"career": "ì‹ ì…"}},
                    {"match": {"career": "ë¬´ê´€"}},
                    {"match": {"career": "ê²½ë ¥ë¬´ê´€"}}
                ],
                "minimum_should_match": 1
            }
        }

    # CASE 2: ì‚¬ìš©ìê°€ ê²½ë ¥ì§ì¸ ê²½ìš° (ìˆ«ì ë…„ì°¨ ì…ë ¥)
    if user_years > 0:
        return {
            "bool": {
                # 'must' ì¡°ê±´: ì‚¬ìš©ìê°€ ì…ë ¥í•œ ê²½ë ¥ í‚¤ì›Œë“œë¥¼ í¬í•¨í•´ì•¼ í•¨
                "must": [
                    {"match": {"career": career}}
                ],
                # 'must_not' ì¡°ê±´: 'ì‹ ì…'ì´ë¼ëŠ” ë‹¨ì–´ê°€ í¬í•¨ëœ ê³µê³ ëŠ” ì œì™¸
                "must_not": [
                    {"match": {"career": "ì‹ ì…"}}
                ]
            }
        }
    
    # ìœ„ ì¡°ê±´ì— í•´ë‹¹í•˜ì§€ ì•Šìœ¼ë©´ í•„í„°ë¥¼ ì ìš©í•˜ì§€ ì•ŠìŒ
    return None

def build_search_query(user_profile: Dict, top_k: int = 5, exclude_ids: list = None) -> Dict:
    """ì—…ê·¸ë ˆì´ë“œëœ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±"""
    if exclude_ids is None:
        exclude_ids = []

    # ì‚¬ìš©ì ì…ë ¥ íŒŒì‹±
    major = user_profile.get("candidate_major", "")
    interest = user_profile.get("candidate_interest", "")
    career = user_profile.get("candidate_career", "")
    tech_stack = " ".join(user_profile.get("candidate_tech_stack", []))
    location = user_profile.get("candidate_location", "")
    query_text = user_profile.get("candidate_question", "")
    
    # ì„ë² ë”© ë²¡í„° ìƒì„±
    embedding_model = get_embedding_model()
    query_vector = embedding_model.encode(f"query: {query_text}").tolist()
    
    # ì œì™¸í•  ë¬¸ì„œ ID ì²˜ë¦¬
    must_not_clauses = []
    if exclude_ids:
        must_not_clauses.append({"ids": {"values": exclude_ids}})
    
    # ê²½ë ¥ í•„í„° ìƒì„±
    filter_clauses = []
    career_filter = _build_career_filter(career)
    if career_filter:
        filter_clauses.append(career_filter)
    
    # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì¿¼ë¦¬
    search_query = {
        "query": {
            "bool": {
                "should": [
                    # í…ìŠ¤íŠ¸ ë§¤ì¹­
                    {"multi_match": {"query": interest, "fields": ["job_name^3", "title^2", "position_detail"], "boost": 3.0}},
                    {"multi_match": {"query": tech_stack, "fields": ["position_detail", "preferred_qualifications", "qualifications"], "boost": 2.5}},
                    {"multi_match": {"query": f"{major}", "fields": ["qualifications", "preferred_qualifications"], "boost": 1.5}},
                    {"match": {"location": {"query": location, "boost": 1.2}}} if location else None,
                    # ë²¡í„° ê²€ìƒ‰
                    {"knn": {"content_embedding": {"vector": query_vector, "k": top_k * 2, "boost": 2.0}}}
                ],
                "filter": filter_clauses,
                "must_not": must_not_clauses,
                "minimum_should_match": 1
            }
        },
        "size": top_k,
        "_source": {"excludes": ["content_embedding"]}
    }
    
    # None ê°’ ì œê±°
    search_query["query"]["bool"]["should"] = [q for q in search_query["query"]["bool"]["should"] if q is not None]
    
    return search_query

def hybrid_search(user_profile: Dict, top_k: int = 5, exclude_ids: list = None, use_reranker: bool = True) -> Tuple[List[float], List[str], List[Dict]]:
    """í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ + ë¦¬ë­í‚¹ ì‹¤í–‰"""
    
    try:
        # 1ë‹¨ê³„: ë” ë§ì€ í›„ë³´ ê²€ìƒ‰ (ë¦¬ë­í‚¹ì„ ìœ„í•´)
        retrieval_k = top_k * 5 if use_reranker else top_k
        if exclude_ids is None:
            exclude_ids = []
        search_query = build_search_query(user_profile, retrieval_k, exclude_ids)
        
        logger.info(f"ğŸ” 1ë‹¨ê³„: OpenSearchì—ì„œ {retrieval_k}ê°œ í›„ë³´ ê²€ìƒ‰ ì¤‘...")
        
        # OpenSearch ê²€ìƒ‰ ì‹¤í–‰
        client = get_opensearch_client()
        response = client.search(
            index=OPENSEARCH_INDEX,
            body=search_query
        )
        
        # ì´ˆê¸° ê²€ìƒ‰ ê²°ê³¼
        initial_hits = response.get("hits", {}).get("hits", [])
        if not initial_hits:
            logger.info("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return [], [], []
        
        logger.info(f"âœ… 1ë‹¨ê³„ ì™„ë£Œ: {len(initial_hits)}ê°œ í›„ë³´ ê²€ìƒ‰ë¨")
        
        if not use_reranker:
            # ë¦¬ë­í‚¹ ì—†ì´ ë°”ë¡œ ë°˜í™˜
            scores = [hit.get("_score", 0.0) for hit in initial_hits]
            doc_ids = [hit.get("_id", "") for hit in initial_hits]
            documents = [hit.get("_source", {}) for hit in initial_hits]
            return scores, doc_ids, documents
        
        # 2ë‹¨ê³„: ë¦¬ë­í‚¹
        logger.info("ğŸ”„ 2ë‹¨ê³„: ë¦¬ë­í‚¹ ì§„í–‰ ì¤‘...")
        
        reranker = get_reranker_model()
        
        # ë¦¬ë­í‚¹ìš© ì¿¼ë¦¬ ìƒì„±
        query_for_rerank = f"{user_profile.get('candidate_interest', '')} {user_profile.get('candidate_question', '')}"
        
        # [ì¿¼ë¦¬, ë¬¸ì„œ] ìŒ ìƒì„±
        sentence_pairs = []
        for hit in initial_hits:
            document_text = format_document_for_reranking(hit.get('_source', {}))
            sentence_pairs.append([query_for_rerank, document_text])
        
        # ë¦¬ë­í‚¹ ì ìˆ˜ ê³„ì‚° (ë°°ì¹˜ í¬ê¸° 4ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½)
        rerank_scores = reranker.predict(sentence_pairs, show_progress_bar=False, batch_size=4)
        
        # ì ìˆ˜ì™€ ë¬¸ì„œë¥¼ ë¬¶ì–´ì„œ ì •ë ¬
        scored_hits = list(zip(rerank_scores, initial_hits))
        scored_hits.sort(key=lambda x: x[0], reverse=True)
        
        # ìµœì¢… top_kê°œ ì„ íƒ
        final_results = scored_hits[:top_k]
        
        scores = [float(score) for score, hit in final_results]
        doc_ids = [hit.get("_id", "") for score, hit in final_results]
        documents = [hit.get("_source", {}) for score, hit in final_results]
        
        logger.info(f"âœ… 2ë‹¨ê³„ ì™„ë£Œ: ìµœì¢… {len(scores)}ê°œ ê²°ê³¼ ë°˜í™˜")
        return scores, doc_ids, documents
        
    except Exception as e:
        logger.error(f"âŒ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return [], [], []

def lambda_handler(event, context):
    """Lambda í•¸ë“¤ëŸ¬"""
    try:
        # ìš”ì²­ ë°ì´í„° íŒŒì‹±
        body = json.loads(event.get('body', '{}'))
        user_profile = body.get('user_profile', {})
        top_k = int(body.get('top_k', 5))
        exclude_ids = body.get('exclude_ids', [])
        
        if not user_profile:
            return {
                'statusCode': 400,
                'headers': {'Content-Type': 'application/json'},
                'body': json.dumps({'error': 'user_profileì´ í•„ìš”í•©ë‹ˆë‹¤'}, ensure_ascii=False)
            }
        
        # í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤í–‰
        scores, doc_ids, documents = hybrid_search(
            user_profile=user_profile,
            top_k=top_k,
            exclude_ids=exclude_ids
        )
        
        # ì‘ë‹µ ë°˜í™˜
        response_data = {
            'scores': scores,
            'doc_ids': doc_ids,
            'documents': documents
        }
        
        return {
            'statusCode': 200,
            'headers': {'Content-Type': 'application/json'},
            'body': json.dumps(response_data, ensure_ascii=False)
        }
        
    except Exception as e:
        logger.error(f"âŒ Lambda ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        return {
            'statusCode': 500,
            'headers': {'Content-Type': 'application/json'},
            'body': json.dumps({'error': 'ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤'}, ensure_ascii=False)
        }